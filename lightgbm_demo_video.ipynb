{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lightgbm_demo_video.ipynb",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/natureLanguageQing/BERT-BiLSTM-CRF-NER/blob/master/lightgbm_demo_video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APlJ5TpeMRiW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time,datetime\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "\n",
        "# 对数据进行排序\n",
        "train = train.sort_values(['deviceid','guid','ts'])\n",
        "test = test.sort_values(['deviceid','guid','ts'])\n",
        "\n",
        "# 查看数据是否存在交集\n",
        "# train deviceid 104736\n",
        "# test deviceid 56681\n",
        "# train&test deviceid 46833\n",
        "# train guid 104333\n",
        "# test guid 56861\n",
        "# train&test guid 46654\n",
        "\n",
        "print('train deviceid',len((set(train['deviceid']))))\n",
        "print('test deviceid',len((set(test['deviceid']))))\n",
        "print('train&test deviceid',len((set(train['deviceid'])&set(test['deviceid']))))\n",
        "print('train guid',len((set(train['guid']))))\n",
        "print('test guid',len((set(test['guid']))))\n",
        "print('train&test guid',len((set(train['guid'])&set(test['guid']))))\n",
        "\n",
        "# 时间格式转化 ts\n",
        "def time_data2(time_sj):\n",
        "    data_sj = time.localtime(time_sj/1000)\n",
        "    time_str = time.strftime(\"%Y-%m-%d %H:%M:%S\",data_sj)\n",
        "    return time_str\n",
        "\n",
        "train['datetime'] = train['ts'].apply(time_data2)\n",
        "test['datetime'] = test['ts'].apply(time_data2)\n",
        "\n",
        "train['datetime'] = pd.to_datetime(train['datetime'])\n",
        "test['datetime'] = pd.to_datetime(test['datetime'])\n",
        "\n",
        "# 时间范围\n",
        "# 2019-11-07 23:59:59 2019-11-10 23:59:59\n",
        "# 2019-11-10 23:59:59 2019-11-11 23:59:59\n",
        "print(train['datetime'].min(),train['datetime'].max())\n",
        "print(test['datetime'].min(),test['datetime'].max())\n",
        "# 7     0.000000\n",
        "# 8     0.107774\n",
        "# 9     0.106327\n",
        "# 10    0.105583\n",
        "\n",
        "# 7          11\n",
        "# 8     3674871\n",
        "# 9     3743690\n",
        "# 10    3958109\n",
        "# 11    3653592\n",
        "\n",
        "train['days'] = train['datetime'].dt.day\n",
        "test['days'] = test['datetime'].dt.day\n",
        "\n",
        "train['flag'] = train['days']\n",
        "test['flag'] = 11\n",
        "\n",
        "# 8 9 10 11\n",
        "data = pd.concat([train,test],axis=0,sort=False)\n",
        "del train,test\n",
        "\n",
        "\n",
        "# 小时信息\n",
        "data['hour'] = data['datetime'].dt.hour\n",
        "data['minute'] = data['datetime'].dt.minute\n",
        "\n",
        "# 缺失值填充\n",
        "data['guid'] = data['guid'].fillna('abc')\n",
        "\n",
        "# 构造历史特征 分别统计前一天 guid deviceid 的相关信息\n",
        "# 8 9 10 11\n",
        "history_9 = data[data['days']==8]\n",
        "history_10 = data[data['days']==9]\n",
        "history_11 = data[data['days']==10]\n",
        "history_12 = data[data['days']==11]\n",
        "del data\n",
        "# 61326\n",
        "# 64766\n",
        "# 66547\n",
        "# 41933\n",
        "# 42546\n",
        "print(len(set(history_9['deviceid'])))\n",
        "print(len(set(history_10['deviceid'])))\n",
        "print(len(set(history_11['deviceid'])))\n",
        "print(len(set(history_12['deviceid'])))\n",
        "print(len(set(history_9['deviceid'])&set(history_10['deviceid'])))\n",
        "print(len(set(history_10['deviceid'])&set(history_11['deviceid'])))\n",
        "print(len(set(history_11['deviceid'])&set(history_12['deviceid'])))\n",
        "\n",
        "# 61277\n",
        "# 64284\n",
        "# 66286\n",
        "# 41796\n",
        "# 42347\n",
        "\n",
        "print(len(set(history_9['guid'])))\n",
        "print(len(set(history_10['guid'])))\n",
        "print(len(set(history_11['guid'])))\n",
        "print(len(set(history_12['guid'])))\n",
        "print(len(set(history_9['guid'])&set(history_10['guid'])))\n",
        "print(len(set(history_10['guid'])&set(history_11['guid'])))\n",
        "print(len(set(history_11['guid'])&set(history_12['guid'])))\n",
        "\n",
        "# 640066\n",
        "# 631547\n",
        "# 658787\n",
        "# 345742\n",
        "# 350542\n",
        "\n",
        "print(len(set(history_9['newsid'])))\n",
        "print(len(set(history_10['newsid'])))\n",
        "print(len(set(history_11['newsid'])))\n",
        "print(len(set(history_12['newsid'])))\n",
        "print(len(set(history_9['newsid'])&set(history_10['newsid'])))\n",
        "print(len(set(history_10['newsid'])&set(history_11['newsid'])))\n",
        "print(len(set(history_11['newsid'])&set(history_12['newsid'])))\n",
        "\n",
        "# deviceid guid timestamp ts 时间特征\n",
        "def get_history_visit_time(data1,date2):\n",
        "    data1 = data1.sort_values(['ts','timestamp'])\n",
        "    data1['timestamp_ts'] = data1['timestamp'] - data1['ts']\n",
        "    data1_tmp = data1[data1['target']==1].copy()\n",
        "    del data1\n",
        "    for col in ['deviceid','guid']:\n",
        "        for ts in ['timestamp_ts']:\n",
        "            f_tmp = data1_tmp.groupby([col],as_index=False)[ts].agg({\n",
        "                '{}_{}_max'.format(col,ts):'max',\n",
        "                '{}_{}_mean'.format(col,ts):'mean',\n",
        "                '{}_{}_min'.format(col,ts):'min',\n",
        "                '{}_{}_median'.format(col,ts):'median'\n",
        "            })\n",
        "        date2 = pd.merge(date2,f_tmp,on=[col],how='left',copy=False)\n",
        "\n",
        "    return date2\n",
        "\n",
        "history_10 = get_history_visit_time(history_9,history_10)\n",
        "history_11 = get_history_visit_time(history_10,history_11)\n",
        "history_12 = get_history_visit_time(history_11,history_12)\n",
        "\n",
        "data = pd.concat([history_10,history_11],axis=0,sort=False,ignore_index=True)\n",
        "data = pd.concat([data,history_12],axis=0,sort=False,ignore_index=True)\n",
        "del history_9,history_10,history_11,history_12\n",
        "\n",
        "data = data.sort_values('ts')\n",
        "data['ts_next'] = data.groupby(['deviceid'])['ts'].shift(-1)\n",
        "data['ts_next_ts'] = data['ts_next'] - data['ts']\n",
        "\n",
        "# 当前一天内的特征 leak\n",
        "for col in [['deviceid'],['guid'],['newsid']]:\n",
        "    print(col)\n",
        "    data['{}_days_count'.format('_'.join(col))] = data.groupby(['days'] + col)['id'].transform('count')\n",
        "\n",
        "\n",
        "# netmodel\n",
        "data['netmodel'] = data['netmodel'].map({'o':1, 'w':2, 'g4':4, 'g3':3, 'g2':2})\n",
        "\n",
        "# pos\n",
        "data['pos'] = data['pos']\n",
        "\n",
        "\n",
        "print('train and predict')\n",
        "X_train = data[data['flag'].isin([9])]\n",
        "X_valid = data[data['flag'].isin([10])]\n",
        "X_test = data[data['flag'].isin([11])]\n",
        "\n",
        "\n",
        "lgb_param = {\n",
        "    'learning_rate': 0.1,\n",
        "    'boosting_type': 'gbdt',\n",
        "    'objective': 'binary',\n",
        "    'metric': 'auc',\n",
        "    'max_depth': -1,\n",
        "    'seed':42,\n",
        "    'boost_from_average':'false',\n",
        "    }\n",
        "\n",
        "\n",
        "feature = [\n",
        "       'pos','netmodel',  'hour', 'minute',\n",
        "       'deviceid_timestamp_ts_max', 'deviceid_timestamp_ts_mean',\n",
        "       'deviceid_timestamp_ts_min', 'deviceid_timestamp_ts_median',\n",
        "       'guid_timestamp_ts_max', 'guid_timestamp_ts_mean',\n",
        "       'guid_timestamp_ts_min', 'guid_timestamp_ts_median',\n",
        "       'deviceid_days_count', 'guid_days_count','newsid_days_count',\n",
        "        'ts_next_ts'\n",
        "           ]\n",
        "target = 'target'\n",
        "\n",
        "\n",
        "lgb_train = lgb.Dataset(X_train[feature].values, X_train[target].values)\n",
        "lgb_valid = lgb.Dataset(X_valid[feature].values, X_valid[target].values, reference=lgb_train)\n",
        "lgb_model = lgb.train(lgb_param, lgb_train, num_boost_round=10000, valid_sets=[lgb_train,lgb_valid],\n",
        "                      early_stopping_rounds=50,verbose_eval=10)\n",
        "\n",
        "p_test = lgb_model.predict(X_valid[feature].values,num_iteration=lgb_model.best_iteration)\n",
        "xx_score = X_valid[[target]].copy()\n",
        "xx_score['predict'] = p_test\n",
        "xx_score = xx_score.sort_values('predict',ascending=False)\n",
        "xx_score = xx_score.reset_index()\n",
        "xx_score.loc[xx_score.index<=int(xx_score.shape[0]*0.103),'score'] = 1\n",
        "xx_score['score'] = xx_score['score'].fillna(0)\n",
        "print(f1_score(xx_score['target'],xx_score['score']))\n",
        "\n",
        "del lgb_train,lgb_valid\n",
        "del X_train,X_valid\n",
        "# 没加 newsid 之前的 f1 score\n",
        "# 0.5129179717875857\n",
        "# 0.5197833317587095\n",
        "# 0.6063125458760602\n",
        "X_train_2 = data[data['flag'].isin([9,10])]\n",
        "\n",
        "\n",
        "lgb_train_2 = lgb.Dataset(X_train_2[feature].values, X_train_2[target].values)\n",
        "lgb_model_2 = lgb.train(lgb_param, lgb_train_2, num_boost_round=lgb_model.best_iteration, valid_sets=[lgb_train_2],verbose_eval=10)\n",
        "\n",
        "p_predict = lgb_model_2.predict(X_test[feature].values)\n",
        "\n",
        "submit_score = X_test[['id']].copy()\n",
        "submit_score['predict'] = p_predict\n",
        "submit_score = submit_score.sort_values('predict',ascending=False)\n",
        "submit_score = submit_score.reset_index()\n",
        "submit_score.loc[submit_score.index<=int(submit_score.shape[0]*0.103),'target'] = 1\n",
        "submit_score['target'] = submit_score['target'].fillna(0)\n",
        "\n",
        "submit_score = submit_score.sort_values('id')\n",
        "submit_score['target'] = submit_score['target'].astype(int)\n",
        "\n",
        "sample = pd.read_csv('./sample.csv')\n",
        "sample.columns = ['id','non_target']\n",
        "submit_score = pd.merge(sample,submit_score,on=['id'],how='left')\n",
        "\n",
        "submit_score[['id','target']].to_csv('./baseline.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6t3uR38-1yWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}